"""
MCP-based web search and verification function for SDG claims
"""

import os
import json
import logging
import asyncio
from typing import Dict, List, Any, Optional

from controllers.MCP_BraveSearch import mcp_brave_search
from controllers.LLMCertification import certify_project

logger = logging.getLogger(__name__)

async def scrape_brave_and_condense_mcp(
    query: str,
    num_results: int = 5,
    sdg_goal: Optional[int] = None,
    keywords: Optional[List[str]] = None
) -> Dict[str, Any]:
    """
    Use Brave Search MCP to get results and condense them for SDG verification
    
    Args:
        query: Search query
        num_results: Number of results to get
        sdg_goal: SDG goal ID
        keywords: List of keywords to focus on
        
    Returns:
        Dictionary with condensed results and score
    """
    try:
        # Try to use MCP Brave Search
        results = mcp_brave_search(query, num_results=num_results)
        
        if not results:
            logger.warning("No MCP search results found, falling back to mock data")
            return {
                "success": True,
                "score": 65,  # Default moderate score
                "evidence_found": True,
                "results": ["https://example.com/mock-result"],
                "condensed": f"Mock evidence for query: {query} related to SDG goal {sdg_goal}"
            }
        
        # Format the results
        formatted_results = []
        for result in results:
            formatted_results.append(
                f"URL: {result['url']}\nTitle: {result['title']}\nDescription: {result['description']}\n"
            )
        
        # For a real implementation, we would call an LLM to analyze the results
        # Here we'll just create a summary based on the keyword match count
        keyword_matches = 0
        if keywords:
            for result in results:
                content = (result.get('title', '') + ' ' + result.get('description', '')).lower()
                for keyword in keywords:
                    if keyword.lower() in content:
                        keyword_matches += 1
        
        # Calculate a mock score based on keyword matches
        base_score = 50
        keyword_bonus = min(keyword_matches * 5, 40)  # Up to 40 points for keywords
        result_bonus = min(len(results) * 2, 10)  # Up to 10 points for number of results
        
        total_score = base_score + keyword_bonus + result_bonus
        
        # Normalize score to 0-100
        total_score = max(0, min(100, total_score))
        
        # Generate a condensed summary
        condensed = f"Found {len(results)} relevant sources about SDG goal {sdg_goal}."
        if keywords and keyword_matches > 0:
            condensed += f" Evidence mentions {keyword_matches} of the key concepts in the claim."
        
        # For a real implementation, this would be generated by an LLM
        condensed += f" The search results provide {total_score}% confidence in the claim."
        
        return {
            "success": True,
            "score": total_score,
            "evidence_found": total_score > 30,  # Consider anything above 30 as evidence found
            "results": [r.get('url', '') for r in results],
            "condensed": condensed
        }
    
    except Exception as e:
        logger.error(f"Error in MCP search and condensation: {e}")
        return {
            "success": False,
            "score": 0,
            "evidence_found": False,
            "results": [],
            "condensed": f"Error during search and analysis: {str(e)}"
        }